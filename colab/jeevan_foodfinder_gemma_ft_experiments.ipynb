{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "1uGJLUgXZgYLJqK6AeSBlUyOCWAfuDdw5",
      "authorship_tag": "ABX9TyNXgbKItHLbasY03sto6lOi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sourcesync/kagglex_gemma/blob/gw%2Finitial/colab/jeevan_foodfinder_gemma_ft_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook demonstrates the following:\n",
        "* tests various fine-tuned Gemma models with a simple food query\n",
        "* teasing model \"hallucination\" and experimenting context-based mitigation"
      ],
      "metadata": {
        "id": "Bmxuzt7M5En9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get access to Gemma via your Kaggle account:\n",
        "* Log into your Kaggle account\n",
        "* Request access to Gemma models using your Kaggle account. You can follow these instructions here: https://www.kaggle.com/code/nilaychauhan/get-started-with-gemma-using-kerasnlp\n",
        "* You need to wait for confirmation. Note that this didn't take too long for me.\n",
        "Create an API key in your Kaggle account you will need later. You can follow these instructions here: https://christianjmills.com/posts/kaggle-obtain-api-key-tutorial/"
      ],
      "metadata": {
        "id": "pBM4eYal5KxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ensure your Colab notebook can access Gemma:\n",
        "* Add the Kaggle API key into your COLAB secrets. You can follow these instructions here: https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0"
      ],
      "metadata": {
        "id": "fLeOrYnc5Q9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Select an AI hardware accelerator\n",
        "* Select hardware options near the top right of your Colab notebook\n",
        "* I tested with A100 and it worked well. Note that I have a Colab Pro subscription."
      ],
      "metadata": {
        "id": "RmGTQG9O5VL-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required packages"
      ],
      "metadata": {
        "id": "gIec-Jop5ZVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!pip install -q -U keras-nlp\n",
        "!pip install -q -U \"keras>=3.3.3\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F69jVyBX5cmr",
        "outputId": "5f6939af-850d-4dae-ccd4-57f03a2d4d34"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 27.7 ms, sys: 6.67 ms, total: 34.4 ms\n",
            "Wall time: 4.82 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required packages"
      ],
      "metadata": {
        "id": "D2kZRgZD5dTL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import keras\n",
        "import keras_nlp\n",
        "from keras_nlp.models import GemmaBackbone, BertBackbone\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "import tensorflow\n",
        "from IPython.display import Markdown, display\n",
        "import textwrap\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import pandas as pd\n",
        "import gc"
      ],
      "metadata": {
        "id": "tvURFK-95fxr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure this notebook\n",
        "* set up KERAS parameters recommended by Google\n",
        "* integrate KAGGLE API secret key"
      ],
      "metadata": {
        "id": "KWJgU7-m5j5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up KERAS parameters recommended by Google\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\" # Avoid memory fragmentation on JAX backend.\n",
        "\n",
        "# integrate KAGGLE API secret key\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get('KAGGLE_USERNAME') # Link to KAGGLE API secret key\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get('KAGGLE_KEY') # Link to KAGGLE API secret key"
      ],
      "metadata": {
        "id": "rsR0dios5udM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define some useful functions"
      ],
      "metadata": {
        "id": "U51huKfz6ETX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_chat(prompt, response):\n",
        "  '''Displays an LLM prompt and response in a pretty way.'''\n",
        "  prompt = prompt.replace('\\n\\n','<br><br>')\n",
        "  prompt = prompt.replace('\\n','<br>')\n",
        "  formatted_prompt = \"<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>\" + prompt + \"</blockquote></font>\"\n",
        "  response = response.replace('‚Ä¢', '  *')\n",
        "  response = textwrap.indent(response, '', predicate=lambda _: True)\n",
        "  response = response.replace('\\n\\n','<br><br>')\n",
        "  response = response.replace('\\n','<br>')\n",
        "  response = response.replace(\"```\",\"\")\n",
        "  formatted_text = \"<font size='+1' color='teal'>ü§ñ<blockquote>\" + response + \"</blockquote></font>\"\n",
        "  return Markdown(formatted_prompt+formatted_text)"
      ],
      "metadata": {
        "id": "jnoSDdGV6FYU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieve the fine-tuning dataset\n",
        "* You will need to first copy it to your gdrive\n",
        "* Then you need to mount your gdrive on the left side panel in your colab notebook\n",
        "* You will likely need to change the path to where you copied it in your gdrive"
      ],
      "metadata": {
        "id": "dLDQD1Dm50y0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# make sure we can access the dataset\n",
        "CSV_PATH=\"/content/drive/MyDrive/Kaggle_X/Jeevan_FoodFinder/qa_pairs_df.csv\"\n",
        "if not os.path.exists(CSV_PATH):\n",
        "  raise Exception(\"Could not find the dataset.\")\n",
        "else:\n",
        "  print(\"Found the dataset.\")\n",
        "\n",
        "# load it via pandas and summarize\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "gmNapYfL54Y7",
        "outputId": "10beaca1-28e0-461f-c0f3-9b1f1ef3b3cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found the dataset.\n",
            "CPU times: user 14.6 ms, sys: 2.64 ms, total: 17.2 ms\n",
            "Wall time: 18.3 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                     question  \\\n",
              "count                                                                    1121   \n",
              "unique                                                                    717   \n",
              "top     What are the overall views of the customers on Sushi Zai in location?   \n",
              "freq                                                                        5   \n",
              "\n",
              "                                           answer  \n",
              "count                                        1121  \n",
              "unique                                        772  \n",
              "top     Sake (Nihonshu),Shochu (Japanese spirits)  \n",
              "freq                                           39  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-efd3032d-0f93-4d20-a382-f02171800366\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1121</td>\n",
              "      <td>1121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>717</td>\n",
              "      <td>772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>What are the overall views of the customers on Sushi Zai in location?</td>\n",
              "      <td>Sake (Nihonshu),Shochu (Japanese spirits)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>5</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-efd3032d-0f93-4d20-a382-f02171800366')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-efd3032d-0f93-4d20-a382-f02171800366 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-efd3032d-0f93-4d20-a382-f02171800366');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-53bfb38c-c1c8-4718-8f9d-ba32848418ce\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-53bfb38c-c1c8-4718-8f9d-ba32848418ce')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-53bfb38c-c1c8-4718-8f9d-ba32848418ce button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"get_ipython()\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          717,\n          \"5\",\n          \"1121\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          772,\n          \"39\",\n          \"1121\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset for fine-tuning"
      ],
      "metadata": {
        "id": "quQ7zeQT62PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)\n",
        "print(df.shape)\n",
        "\n",
        "template = \"Instruction:\\n{question}\\n\\nResponse:\\n{answer}\"\n",
        "\n",
        "# format each training string, put them all into a list\n",
        "ft_data = []\n",
        "for idx, row in df.iterrows():\n",
        "  ft_item = template.format(question=row['question'], answer=row['answer'])\n",
        "  ft_data.append(ft_item)\n",
        "\n",
        "# double-check\n",
        "print(ft_data[0])\n",
        "print(\"----\")\n",
        "print(ft_data[-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnOMhr4K67JK",
        "outputId": "9a229e52-96d9-4712-98dd-b92ec78c35f7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1121, 2)\n",
            "Instruction:\n",
            "What type of food does the restaurant Bistro Sakaba REPOS in the  Sapporo region of Hokkaido serve?\n",
            "\n",
            "Response:\n",
            "Bistro, Italian, Bar\n",
            "----\n",
            "Instruction:\n",
            "What are the top rated restaurants in Tokyo?\n",
            "\n",
            "Response:\n",
            "Bia, Yoroniku, Sushi Zai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Gemma 2b base"
      ],
      "metadata": {
        "id": "uzrAEdvK6Xxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")\n",
        "# uncomment the following lines to \"sample the softmax probabilities of the model\"\n",
        "#sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
        "#gemma_lm.compile(sampler=sampler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZfMWVNJ6bSw",
        "outputId": "6279e91f-f359-49e1-85f5-83dc9d1d27a3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.51 s, sys: 9.94 s, total: 19.4 s\n",
            "Wall time: 43 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enable the model for fine-tuning"
      ],
      "metadata": {
        "id": "ozTgQtYa6raa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.backbone.enable_lora(rank=4)"
      ],
      "metadata": {
        "id": "MeTnhpOH6tpu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune the base model"
      ],
      "metadata": {
        "id": "ED67UQJi6u7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Limit the input sequence length to X (to control memory usage).\n",
        "gemma_lm.preprocessor.sequence_length = 1024\n",
        "# Use AdamW (a common optimizer for transformer models).\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "# Exclude layernorm and bias terms from decay.\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
        "\n",
        "gemma_lm.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=optimizer,\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "gemma_lm.fit(ft_data, epochs=1, batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SINrITcg6zrW",
        "outputId": "c9b14830-c6dd-440d-d5a9-4681ad822d77"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1121/1121\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 122ms/step - loss: 0.1763 - sparse_categorical_accuracy: 0.5483\n",
            "CPU times: user 3min 39s, sys: 8.37 s, total: 3min 48s\n",
            "Wall time: 3min 7s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7842ec418c10>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test model with some queries"
      ],
      "metadata": {
        "id": "qwRiHhwT93s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format(\n",
        "    question=\"What food type is popular in Japan?\",\n",
        "    answer=\"\",\n",
        ")\n",
        "completion = gemma_lm.generate(prompt, max_length=1024)\n",
        "response = completion.replace(prompt, \"\")\n",
        "display_chat(prompt, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "NJhjTLXr966f",
        "outputId": "a9d3b3f4-4867-40c4-c76a-0c7a46899acd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>Instruction:<br>What food type is popular in Japan?<br><br>Response:<br></blockquote></font><font size='+1' color='teal'>ü§ñ<blockquote>Sushi</blockquote></font>"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format(\n",
        "    question=\"What should I eat in Japan?\",\n",
        "    answer=\"\",\n",
        ")\n",
        "completion = gemma_lm.generate(prompt, max_length=1024)\n",
        "response = completion.replace(prompt, \"\")\n",
        "display_chat(prompt, response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "tcsJchH7_lIL",
        "outputId": "1003a695-263e-4753-9d7f-2523aefbf19e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>Instruction:<br>What should I eat in Japan?<br><br>Response:<br></blockquote></font><font size='+1' color='teal'>ü§ñ<blockquote>The Japanese cuisine is known for its simplicity and elegance. The dishes are often made with fresh, seasonal ingredients, and the flavors are balanced and refined. Some of the most popular dishes in Japan include sushi, sashimi, tempura, and grilled meats.</blockquote></font>"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format(\n",
        "    question=\"What should I eat in Greenland?\",\n",
        "    answer=\"\",\n",
        ")\n",
        "completion = gemma_lm.generate(prompt, max_length=1024)\n",
        "response = completion.replace(prompt, \"\")\n",
        "display_chat(prompt, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "lAMl6MzhAujH",
        "outputId": "233889a1-0dc3-40ae-e108-9a5f346f5be5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>Instruction:<br>What should I eat in Greenland?<br><br>Response:<br></blockquote></font><font size='+1' color='teal'>ü§ñ<blockquote>The food in Greenland is a mix of traditional Inuit cuisine and modern European influences. Some popular dishes include smoked salmon, reindeer meat, and Arctic char. The cuisine is known for its hearty and flavorful dishes, with a focus on fresh and local ingredients.</blockquote></font>"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coax the model to \"hallucinate\" by asking about a fictional place"
      ],
      "metadata": {
        "id": "3zr9Axj8CEpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format(\n",
        "    question=\"What should I eat in Westeros?\",\n",
        "    answer=\"\",\n",
        ")\n",
        "completion = gemma_lm.generate(prompt, max_length=1024)\n",
        "response = completion.replace(prompt, \"\")\n",
        "display_chat(prompt, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "9o7aPUmFA9ZS",
        "outputId": "4aa4f37d-8dd6-48da-9fa7-966783b299db"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>Instruction:<br>What should I eat in Westeros?<br><br>Response:<br></blockquote></font><font size='+1' color='teal'>ü§ñ<blockquote>The food in Westeros is a mix of traditional and modern dishes. Some of the most popular dishes include chicken, beef, pork, and fish. There are also a variety of soups, stews, and side dishes. The cuisine is often hearty and flavorful, with a focus on fresh ingredients and local flavors.</blockquote></font>"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coax the model to \"hallucinate\" by asking about a fictional place not likely seen in pre-training"
      ],
      "metadata": {
        "id": "qNCVzgNJMfy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format(\n",
        "    question=\"What should I eat in when I visit Blahlabhlah?\",\n",
        "    answer=\"\",\n",
        ")\n",
        "completion = gemma_lm.generate(prompt, max_length=1024)\n",
        "response = completion.replace(prompt, \"\")\n",
        "display_chat(prompt, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "N9gRQ0zeMrXP",
        "outputId": "98f50ca6-f112-449b-e24f-1962ac848431"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>Instruction:<br>What should I eat in when I visit Blahlabhlah?<br><br>Response:<br></blockquote></font><font size='+1' color='teal'>ü§ñ<blockquote>The restaurant offers a variety of dishes, including grilled meat, seafood, and vegetables. The menu also features a selection of traditional Korean dishes, such as bibimbap and bulgogi.</blockquote></font>"
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mitigate \"hallucination\" by providing useful context"
      ],
      "metadata": {
        "id": "N_RrQFR6Mvgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_template=\"{pre}\\n\\nContext:\\n{context}\\n\\n{prompt}\"\n",
        "\n",
        "full_prompt = full_template.format(\n",
        "    pre=\"Use the following context to respond to the instruction.\",\n",
        "    context='''Blahblahblah is a fictional place. '''\n",
        "      ''' People who live in Blahblalblah eat mutton and dragon meat.'''\n",
        "      ''' Some people who live in Blahblahblah eat sushi.'''\n",
        "      ''' You should try mutton and dragon meat if you find yourself in Blahblahblah.''',\n",
        "    prompt=prompt\n",
        ")\n",
        "completion = gemma_lm.generate(full_prompt, max_length=1024)\n",
        "response = completion.replace(full_prompt, \"\")\n",
        "display_chat(full_prompt, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "WktirUojMy88",
        "outputId": "6a11502c-337b-4ab1-bc26-bec38c2c0e40"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>Use the following context to respond to the instruction.<br><br>Context:<br>Blahblahblah is a fictional place.  People who live in Blahblalblah eat mutton and dragon meat. Some people who live in Blahblahblah eat sushi. You should try mutton and dragon meat if you find yourself in Blahblahblah.<br><br>Instruction:<br>What should I eat in when I visit Blahlabhlah?<br><br>Response:<br></blockquote></font><font size='+1' color='teal'>ü§ñ<blockquote>I should eat mutton and dragon meat.</blockquote></font>"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Gemma 2B instr"
      ],
      "metadata": {
        "id": "LsTGTBF1CyGR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")\n",
        "# uncomment the following lines to \"sample the softmax probabilities of the model\"\n",
        "#sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
        "#gemma_lm.compile(sampler=sampler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I12MVsygC15W",
        "outputId": "461da7d1-552b-4669-f93d-8b9bae8998b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 9.58 s, sys: 8.7 s, total: 18.3 s\n",
            "Wall time: 19.1 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enable fine-tuning"
      ],
      "metadata": {
        "id": "jw-Mx6luFFp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gemma_lm.backbone.enable_lora(rank=4)"
      ],
      "metadata": {
        "id": "e9K750SjFHhm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tune the already instruction tuned model"
      ],
      "metadata": {
        "id": "hHpvNg5_FLyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Limit the input sequence length to X (to control memory usage).\n",
        "gemma_lm.preprocessor.sequence_length = 1024\n",
        "# Use AdamW (a common optimizer for transformer models).\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "    learning_rate=5e-5,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "# Exclude layernorm and bias terms from decay.\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
        "\n",
        "gemma_lm.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=optimizer,\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        ")\n",
        "gemma_lm.fit(ft_data, epochs=1, batch_size=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbz77u-sFNoY",
        "outputId": "6f27949d-db67-4c4a-8f0e-92a7236027ff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1121/1121\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 122ms/step - loss: 0.2004 - sparse_categorical_accuracy: 0.5854\n",
            "CPU times: user 3min 39s, sys: 8.53 s, total: 3min 48s\n",
            "Wall time: 3min 7s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c5a94668490>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coax \"hallucination\""
      ],
      "metadata": {
        "id": "gqmY6sfEGa78"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = template.format(\n",
        "    question=\"What should I eat in when I visit Blahlabhlah?\",\n",
        "    answer=\"\",\n",
        ")\n",
        "completion = gemma_lm.generate(prompt, max_length=1024)\n",
        "response = completion.replace(prompt, \"\")\n",
        "display_chat(prompt, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "YpWO9qWNGdAP",
        "outputId": "ff71469f-727a-4420-96a5-d686d0a1a72d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>Instruction:<br>What should I eat in when I visit Blahlabhlah?<br><br>Response:<br></blockquote></font><font size='+1' color='teal'>ü§ñ<blockquote>The restaurant serves a variety of dishes, but the most popular are the grilled fish and the grilled pork.</blockquote></font>"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mitigate \"hallucination\" with context"
      ],
      "metadata": {
        "id": "ScrBQM2SGtl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_template=\"{pre}\\n\\nContext:\\n{context}\\n\\n{prompt}\"\n",
        "\n",
        "full_prompt = full_template.format(\n",
        "    pre=\"Use the following context to respond to the instruction.\",\n",
        "    context='''Blahblahblah is a fictional place. '''\n",
        "      ''' People who live in Blahblalblah eat mutton and dragon meat.'''\n",
        "      ''' Some people who live in Blahblahblah eat sushi.'''\n",
        "      ''' You should try mutton and dragon meat if you find yourself in Blahblahblah.''',\n",
        "    prompt=prompt\n",
        ")\n",
        "completion = gemma_lm.generate(full_prompt, max_length=1024)\n",
        "response = completion.replace(full_prompt, \"\")\n",
        "display_chat(full_prompt, response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "k-nV4XHcGyfs",
        "outputId": "1c9098b4-54da-434e-e26b-3ade85fe30a3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "<font size='+1' color='brown'>üôã‚Äç‚ôÇÔ∏è<blockquote>Use the following context to respond to the instruction.<br><br>Context:<br>Blahblahblah is a fictional place.  People who live in Blahblalblah eat mutton and dragon meat. Some people who live in Blahblahblah eat sushi. You should try mutton and dragon meat if you find yourself in Blahblahblah.<br><br>Instruction:<br>What should I eat in when I visit Blahlabhlah?<br><br>Response:<br></blockquote></font><font size='+1' color='teal'>ü§ñ<blockquote>Mutton and dragon meat</blockquote></font>"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}