{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89141b96-e60c-4909-91ee-37aaa7383adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  This notebook demonstrates the following:\n",
    "#  * Loads the model 'gemma_instruct_2b_en' via Keras\n",
    "#  * Shows various methods to complete a prompt\n",
    "#    * model generate() method\n",
    "#    * Langchain Runnable class\n",
    "#    * GemmaLocalKaggle\n",
    "#    * GemmaChatLocalKaggle\n",
    "#  * Experiments with ways to integrate conversation history\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2b68d11-29a0-4c0e-aa52-54b21b16d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Python imports\n",
    "#\n",
    "#  Notes:\n",
    "#  * Make sure you install the packages in requirements.txt\n",
    "#  * Make sure you setup your KAGGLE secrets via env vars.\n",
    "#\n",
    "import os\n",
    "import keras\n",
    "import keras_nlp\n",
    "from keras_nlp.models import GemmaBackbone, BertBackbone\n",
    "from keras.models import load_model\n",
    "import kagglehub\n",
    "from langchain.schema.runnable import Runnable\n",
    "from typing import Any, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0e6c309-c3f4-41c3-8af0-608a4ddc0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Global config\n",
    "#\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\" # Suppress annoying low-level GRPC warnings\n",
    "os.environ[\"GLOG_minloglevel\"] = \"2\"   # Suppress annoying low-level GLOG warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6427861e-d331-4308-bb78-49d356ced65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Initial prompt - I'll use this prompt to contrast-and-compare various \n",
    "# prompt completion techniques using Keras\n",
    "#\n",
    "initial_prompt = \"Tell me a story. My name is Daniel.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a19460-4b94-4b8f-805a-b7d086975f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726863232.248734 11654186 service.cc:146] XLA service 0x6000028bc400 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1726863232.248753 11654186 service.cc:154]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1726863232.252651 11654186 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " \"Tell me a story. My name is Daniel.\"\n",
      "\n",
      "Completion:\n",
      " \"Tell me a story. My name is Daniel.\n",
      "I was born and raised in a small coastal town in California called Santa Cruz. The ocean was my playground, and I spent countless hours swimming, surfing, and playing in the waves. I had a deep love for the ocean and all it had to offer.\n",
      "One fateful day, a storm hit Santa Cruz with devastating force. The powerful waves crashed over the coastline, destroying everything in their path. My beloved town was devastated, and I was heartbroken.\n",
      "But through the devastation, there were also glimmers of hope. The ocean had a way of reclaiming what it had lost, and new life emerged in the aftermath. The town was rebuilt, stronger than ever before.\n",
      "As I grew older, I realized that my passion for the sea had not changed. I still yearned for the calmness and beauty of the ocean, and I found solace in the memories of my childhood.\n",
      "Years later, I returned to Santa Cruz to rebuild my life. I had learned from my previous experience and was determined to make the town a better place for all.\n",
      "I started by creating a community garden, where people could come together and share their passion for nature. I also launched a youth sailing program, which aimed to introduce young people to the joy of sailing.\n",
      "The town was slowly but surely recovering, and I was proud to be a part of it. I had not only lost my hometown but had also gained a new sense of purpose.\n",
      "One day, I received a letter from a former student who had moved away. They told me that they were now a successful marine biologist, and they thanked me for inspiring them to pursue their dream.\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean.\n",
      "I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\"\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  Test a basic prompt completion using the model generate() call\n",
    "#\n",
    "template = \"{instruction}\" # Note: format may depend on the fine-tuning dataset format\n",
    "simple_prompt = template.format(\n",
    "    instruction=initial_prompt,\n",
    "    response=\"\",\n",
    ")\n",
    "model_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=3, seed=2)\n",
    "model_lm.compile(sampler=sampler)\n",
    "prompt_completion = model_lm.generate(simple_prompt, max_length=2048) # Note: Using the context size of Gemma as max\n",
    "model_prompt_completion = prompt_completion.replace(\"\\n\\n\",\"\\n\") # remove double new-lines for prettier printing here\n",
    "print(\"Prompt:\\n\", \"\\\"\" + simple_prompt + \"\\\"\")\n",
    "print(\"\\nCompletion:\\n\", \"\\\"\"+model_prompt_completion+\"\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26310572-7581-4eb2-9ca9-6200431b9151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runnable prompt:\n",
      "\"Tell me a story. My name is Daniel.\"\n",
      "\n",
      "Runnable completion:\n",
      "\"Tell me a story. My name is Daniel.\n",
      "\n",
      "My life was filled with the mundane. My days were filled with work, errands, and a never-ending cycle of chores. But there was one bright spot in my otherwise ordinary existence: a small garden tucked away in the corner of my backyard.\n",
      "\n",
      "One sunny afternoon, I decided to explore the garden. I had never been there before, and I was amazed by the vibrant flowers and the lush greenery. I felt a sense of peace and tranquility wash over me as I sat down and took in the beauty of my surroundings.\n",
      "\n",
      "As I sat there, I heard a gentle breeze rustling through the leaves. It was then that I noticed a small, furry creature scurrying across the garden path. It was the cutest little squirrel I had ever seen, and I reached out my hand to pet its head.\n",
      "\n",
      "The squirrel was startled but seemed to sense my good intentions. It wagged its tail and let out a tiny squeak, as if to say hello. I smiled warmly and reached out to stroke its fur.\n",
      "\n",
      "From that day forward, the squirrel became my best friend. We met daily in the garden, and we had countless adventures together. I learned so much from this little creature, about the world and about myself.\n",
      "\n",
      "One day, I decided to take the squirrel to the vet for a checkup. The vet was amazed by the bond between us and told me that it was the strongest bond he had ever seen between a human and an animal.\n",
      "\n",
      "I was so grateful to have found this special squirrel in my backyard. He brought so much joy and meaning into my life, reminding me that there is always something new and exciting to learn.\n",
      "\n",
      "And so, my life, which had once been filled with the mundane, became a beautiful symphony of joy and wonder thanks to the little squirrel I had met all those years ago.\"\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Test a basic prompt completion a minimal Langchain Runnable\n",
    "#\n",
    "class LMRunnable(Runnable):\n",
    "    def __init__(self, model: keras_nlp.models.GemmaCausalLM):\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, input: Any, config: Optional[dict] = None) -> str:\n",
    "        prompt = str(input)\n",
    "        output = self.model.generate(prompt, max_length=2048)\n",
    "        return output if isinstance(output,str) else \"Unknown output type.\"\n",
    "\n",
    "# Use the (previously compiled) Gemma model as a Langchain Runnable\n",
    "runnable = LMRunnable(model_lm)\n",
    "\n",
    "# Complete the prompt via Runnable invoke()\n",
    "runnable_prompt = f\"{initial_prompt}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(\"Runnable prompt:\\n\" + \"\\\"\" +runnable_prompt + \"\\\"\")\n",
    "runnable_prompt_completion = runnable.invoke(runnable_prompt)\n",
    "print(\"\\nRunnable completion:\\n\" + \"\\\"\" + runnable_prompt_completion + \"\\\"\")\n",
    "\n",
    "runnable = None # clean up memory\n",
    "model_lm = None # clean up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e3f86c6-1e2c-4395-96ef-3adf4cef1097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GemmaLocalKaggle prompt:\n",
      "\"Tell me a story. My name is Daniel.\"\n",
      "\n",
      "GemmaLocalKaggle completion:\n",
      " Tell me a story. My name is Daniel.\n",
      "\n",
      "I woke up in a small cottage nestled amongst the rolling hills. The morning sun painted the walls with warm golden hues, and the birds sang melodies that filled the air with joy.\n",
      "\n",
      "As I opened my eyes, I noticed a small cottage nestled amongst the rolling hills. The cottage was made of wood and stone, with a thatched roof that seemed to dance in the sunlight. A small door was open, inviting me inside.\n",
      "\n",
      "I stepped through the door and into the cozy interior. The walls were adorned with paintings of animals and landscapes, and the floor was covered with a soft rug. A fireplace crackled in the corner, casting warm shadows on the walls.\n",
      "\n",
      "A warm meal awaited me in the kitchen, along with a cozy bed to rest my head. I sat down at the table and enjoyed the simple yet delicious meal.\n",
      "\n",
      "As the sun began to set, I took a stroll outside the cottage, enjoying the fresh air and the stunning views. I watched as the birds flew around the hills, their colors shimmering in the golden light.\n",
      "\n",
      "That day, I learned the name of the cottage and the surrounding area. I met the kind old farmer who lived there, who welcomed me into his home and shared stories of the land.\n",
      "\n",
      "I spent the next few days exploring the area, discovering hidden waterfalls, lush forests, and charming villages. I learned about the local culture and traditions, and I made memories that would last a lifetime.\n",
      "\n",
      "One evening, as I sat by the fireplace, I heard a soft melody echoing through the hills. I followed the sound to a hidden spot, where I found a small cottage with a beautiful garden. The cottage belonged to a young woman named Sarah, who welcomed me in and showed me around her home.\n",
      "\n",
      "We talked for hours, sharing stories and laughter. I learned about her life, her dreams, and her aspirations. I was struck by her kindness and warmth, and I felt a deep connection to her.\n",
      "\n",
      "As the sun rose the next morning, I bid farewell to Sarah and the charming cottage. I knew that I would cherish the memories I had made during my stay.\n",
      "\n",
      "And so, my journey began, guided by the gentle hand of the sun and the kindness of strangers. I was Daniel, a traveler who found a home in the rolling hills and the hearts of the people I met along the way.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Test a basic prompt completion using Langchain's GemmaLocalKaggle class\n",
    "# Documenation: https://python.langchain.com/api_reference/google_vertexai/gemma/langchain_google_vertexai.gemma.GemmaLocalKaggle.html\n",
    "#\n",
    "from langchain_google_vertexai import GemmaLocalKaggle\n",
    "glk_model = GemmaLocalKaggle(model_name=\"gemma_instruct_2b_en\", keras_backend=\"jax\")\n",
    "glk_prompt = f\"{initial_prompt}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(\"GemmaLocalKaggle prompt:\\n\" + \"\\\"\" + glk_prompt + \"\\\"\")\n",
    "glk_prompt_completion = glk.invoke(glk_prompt)\n",
    "print(\"\\nGemmaLocalKaggle completion:\\n\", glk_prompt_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b44272d4-707f-4a45-8969-bcfb9d18211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GemmaChatLocalKaggle prompt: Tell me a story. My name is Daniel.\n",
      "\n",
      "GemmaChatLocalKaggle aimessage response object:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<start_of_turn>user\n",
      "Tell me a story. My name is Daniel.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "My name is Daniel, and I have a story to tell. I was born in a small village nestled amidst rolling hills and shimmering rivers. My childhood was filled with laughter and adventure, as I explored the lush forests and hidden waterfalls that surrounded our home.\n",
      "\n",
      "As I grew older, I became fascinated by the world beyond our village. I would spend countless hours gazing up at the vast expanse of the sky, wondering about the mysteries of the universe. My curiosity led me to explore nearby towns and cities, where I learned about different cultures and traditions.\n",
      "\n",
      "My thirst for knowledge never waned. I enrolled in a prestigious university, where I excelled in my studies. I was particularly drawn to the field of literature, where I discovered the power of words to transport me to different worlds and inspire me to think differently.\n",
      "\n",
      "After graduating, I returned to my village and took up a teaching position in a local school. I found joy in sharing my love of learning with young minds, and I became known for my patience and dedication.\n",
      "\n",
      "As the years passed, I met a wonderful woman named Sarah. We fell deeply in love and got married. We built a life together, filled with laughter, adventure, and a deep sense of connection.\n",
      "\n",
      "Through the years, I faced challenges and celebrated triumphs. I traveled the world, exploring different cultures and making lifelong friends. I learned the importance of compassion, forgiveness, and the power of kindness.\n",
      "\n",
      "Now, as an older man, I reflect on my life with gratitude. I have lived a full and meaningful life, surrounded by love and surrounded by the beauty of nature. I am proud of the person I have become, and I am eager to continue sharing my story with the world.\n",
      "\n",
      "My story is a testament to the power of curiosity, the importance of lifelong learning, and the enduring strength of love. It is a story that I will continue to tell, for it is a story that belongs to all of us.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Test a basic prompt completion using Langchain's GemmaChatLocalKaggle class\n",
    "# Documentation: https://python.langchain.com/api_reference/google_vertexai/gemma/langchain_google_vertexai.gemma.GemmaChatLocalKaggle.html\n",
    "#\n",
    "from langchain_google_vertexai import GemmaChatLocalKaggle\n",
    "gclk_model = GemmaChatLocalKaggle(model_name=\"gemma_instruct_2b_en\", keras_backend=\"jax\")\n",
    "gclk_prompt = f\"{initial_prompt}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(\"GemmaChatLocalKaggle prompt:\", gclk_prompt)\n",
    "ai_message = gclk.invoke(gclk_prompt) # return a special aimessage object\n",
    "print(\"\\nGemmaChatLocalKaggle aimessage response object:\")\n",
    "ai_message.pretty_print()\n",
    "# extract just the model completion from aimessage - vertexai appears to insert \"turn\" tags\n",
    "turn_prefix = \"<start_of_turn>model\\n\"\n",
    "pos = ai_message.content.find(turn_prefix)\n",
    "gclk_prompt_completion = ai_message.content[ pos + len(response_prefix): ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc0de4a5-ad8e-47e0-9fa3-035a8dfca22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The rest of this notebook attempts to integrate previous \"chat\" history\n",
    "# in various ways.    \n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a46763e-608a-4228-8b36-e771d98193b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**What is the next part of the story?**I turned to the sky and looked up, admiring the vast expanse of the ocean. I thought about the countless adventures I had had in this vast world, and I felt a deep sense of gratitude for the beauty and wonder that surrounded me. I knew that my story was one of hope, resilience, and the enduring power of the ocean. I would always be proud of my roots, and I would always find solace in the vastness of the ocean.\n"
     ]
    }
   ],
   "source": [
    "# Extract the last two sentences of previous response as 'context' for the next prompt\n",
    "# in the conversation/story.\n",
    "cherry_picked_history = \"\".join( prompt_completion.strip().split(\"\\n\\n\")[-2:] )\n",
    "print(cherry_picked_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ffee5d4-b30e-4b8e-ab0a-883de0da9435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuation prompt:\n",
      " You are a storyteller.  Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean.I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\n",
      "\n",
      "Prompt completion:\n",
      " \"You are a storyteller.  Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean.I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\n",
      "\n",
      "I was born and raised in the heart of the bustling city life, yet I always found myself drawn to the serenity of the ocean and the vastness of nature. The ocean was my sanctuary, my escape, and my guiding light.\n",
      "\n",
      "As I grew older, my curiosity led me to explore the world beyond the city walls. I traveled to distant islands, where I witnessed the breathtaking beauty of coral reefs and the vibrant colors of marine life. I learned about the importance of protecting the ocean, and I vowed to use my voice to raise awareness about the threats facing our planet.\n",
      "\n",
      "Years later, I returned to my roots, where I established a small aquarium and a coral reef rehabilitation center. I was determined to give back to my community and help protect the ocean that had given me so much.\n",
      "\n",
      "Today, I stand as a testament to the enduring power of hope, resilience, and the ocean. I am a storyteller, sharing my experiences and inspiring others to appreciate and protect the precious gift that is the ocean.\n",
      "\n",
      "And so, I tell you, my story is one of hope, resilience, and the enduring power of the ocean.\"\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Continution via model generate()\n",
    "#\n",
    "\n",
    "# Extract the last two sentences of previous response as 'context' for the next prompt in the conversation/story.\n",
    "cherry_picked_history = \"\".join( model_prompt_completion.strip().split(\"\\n\\n\")[-2:] )\n",
    "print(cherry_picked_history)\n",
    "\n",
    "# Form the follow-up prompt.\n",
    "continuation_prompt = template.format(\n",
    "    instruction= f\"You are a storyteller.  Use the following context and continue telling the story.\\n\\n{cherry_picked_history}\",\n",
    "    response=\"\",\n",
    ") # Note: That format may depend additional on the dataset used for fine-tuning\n",
    "print(\"Continuation prompt:\\n\", continuation_prompt)\n",
    "\n",
    "model_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=3, seed=2)\n",
    "model_lm.compile(sampler=sampler)\n",
    "model_continuation_prompt_completion = model_lm.generate(continuation_prompt, max_length=2048) \n",
    "print(\"\\nPrompt completion:\\n\", \"\\\"\"+model_continuation_prompt_completion+\"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71cae5fe-9823-45c5-a3a5-80fe87fa7bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuation prompt:\n",
      " You are a storyteller.  Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean.I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\n",
      "\n",
      "Prompt completiont:\n",
      " You are a storyteller.  Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean.I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\n",
      "\n",
      "The ocean was my playground, and the waves were my teachers. They taught me the rhythm of the tides, the secrets of the currents, and the importance of always being prepared for whatever came my way.\n",
      "\n",
      "As I grew older, I became a skilled fisherman, learning the art of casting my net and reeling in the bounty of the sea. I learned the language of the ocean, understanding its moods and predicting its changes.\n",
      "\n",
      "Years later, I became a renowned diver, exploring the depths of the Mariana Trench, the world's deepest point. I discovered a whole world teeming with life and a treasure trove of lost treasures.\n",
      "\n",
      "One day, a ship appeared on the horizon, bearing a distress signal. I raced to the scene and rescued the crew, saving countless lives. The grateful crew cheered as I saved them, and I realized that my true calling was not just to fish or to explore the depths of the sea, but to help others in need.\n",
      "\n",
      "And so, I became a lighthouse, guiding sailors through treacherous waters and illuminating the path to safety. My story became a beacon of hope, reminding everyone that even in the darkest of times, there is always a light to guide them through the waves.\n",
      "\n",
      "As the sun began to set on the horizon, I looked up and smiled, knowing that my story was one of hope, resilience, and the enduring power of the ocean.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Continuation via a basic Langchain Runnable\n",
    "#\n",
    "class LMRunnable(Runnable):\n",
    "    def __init__(self, model: keras_nlp.models.GemmaCausalLM):\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, input: Any, config: Optional[dict] = None) -> str:\n",
    "        prompt = str(input)\n",
    "        output = self.model.generate(prompt, max_length=2048)\n",
    "        return output if isinstance(output,str) else \"Unknown output type.\"\n",
    "\n",
    "# Use the (previously compiled) Gemma model as a Langchain Runnable\n",
    "runnable = LMRunnable(model_lm)\n",
    "\n",
    "# Complete the prompt via Runnable invoke()\n",
    "continuation_prompt = f\"You are a storyteller.  Use the following context and continue telling the story.\\n\\n{cherry_picked_history}\"\n",
    "print(\"Continuation prompt:\\n\", continuation_prompt)\n",
    "runnable_prompt_completion = runnable.invoke(continuation_prompt)\n",
    "print(\"\\nPrompt completiont:\\n\", runnable_prompt_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca1586a-c934-475c-9d92-5642147623f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GemmaLocalKaggle prompt:\n",
      "\"You are a storyteller.  Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean.I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\"\n",
      "\n",
      "GemmaLocalKaggle completion:\n",
      " You are a storyteller.  Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean.I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\n",
      "\n",
      "**What happened next?**\n",
      "\n",
      "I stood on the shore, watching the waves caress the shore, carrying away the worries of the world. The sun was shining brightly, casting a warm glow on the sand, and the air was filled with the sound of birds singing. I smiled, feeling a sense of contentment wash over me.\n",
      "\n",
      "**What is the next part of the story?**\n",
      "\n",
      "I turned to the sky and looked up, admiring the vast expanse of the ocean. I thought about the countless adventures I had had in this vast world, and I felt a deep sense of gratitude for the beauty and wonder that surrounded me. I knew that my story was one of hope, resilience, and the enduring power of the ocean. I would always be proud of my roots, and I would always find solace in the vastness of the ocean.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Continuation via Langchain's GemmaLocalKaggle class\n",
    "# Documenation: https://python.langchain.com/api_reference/google_vertexai/gemma/langchain_google_vertexai.gemma.GemmaLocalKaggle.html\n",
    "#\n",
    "from langchain_google_vertexai import GemmaLocalKaggle\n",
    "glk_model = GemmaLocalKaggle(model_name=\"gemma_instruct_2b_en\", keras_backend=\"jax\")\n",
    "glk_continuation_prompt = f\"You are a storyteller.  Use the following context and continue telling the story.\\n\\n{cherry_picked_history}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(\"GemmaLocalKaggle prompt:\\n\" + \"\\\"\" + glk_continuation_prompt + \"\\\"\")\n",
    "glk_prompt_completion = glk_model.invoke(glk_continuation_prompt)\n",
    "print(\"\\nGemmaLocalKaggle completion:\\n\", glk_prompt_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017488af-d84c-4acf-a289-6b37b62c8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Test a basic prompt completion using Langchain's GemmaChatLocalKaggle class\n",
    "# Documentation: https://python.langchain.com/api_reference/google_vertexai/gemma/langchain_google_vertexai.gemma.GemmaChatLocalKaggle.html\n",
    "#\n",
    "from langchain_google_vertexai import GemmaChatLocalKaggle\n",
    "gclk_model = GemmaChatLocalKaggle(model_name=\"gemma_instruct_2b_en\", keras_backend=\"jax\")\n",
    "gclk_prompt = f\"{initial_prompt}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(\"GemmaChatLocalKaggle prompt:\", gclk_prompt)\n",
    "ai_message = gclk.invoke(gclk_prompt) # return a special aimessage object\n",
    "print(\"\\nGemmaChatLocalKaggle aimessage response object:\")\n",
    "ai_message.pretty_print()\n",
    "# extract just the model completion from aimessage - vertexai appears to insert \"turn\" tags\n",
    "turn_prefix = \"<start_of_turn>model\\n\"\n",
    "pos = ai_message.content.find(turn_prefix)\n",
    "gclk_prompt_completion = ai_message.content[ pos + len(response_prefix): ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
