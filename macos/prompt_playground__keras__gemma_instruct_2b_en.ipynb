{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89141b96-e60c-4909-91ee-37aaa7383adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  This notebook demonstrates the following:\n",
    "#  * Use the Keras built-in Gemma instruction fine-tuned model ('gemma_instruct_2b_en')\n",
    "#  * Shows various methods to complete a prompt in Keras\n",
    "#    * model generate() method\n",
    "#    * Langchain Runnable class\n",
    "#    * GemmaLocalKaggle\n",
    "#    * GemmaChatLocalKaggle\n",
    "#  * Experiments with ways to integrate conversation history\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2b68d11-29a0-4c0e-aa52-54b21b16d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Python imports\n",
    "#\n",
    "#  Notes:\n",
    "#  * Make sure you install the packages in requirements.txt\n",
    "#  * Make sure you setup your KAGGLE secrets via env vars.\n",
    "#\n",
    "import os\n",
    "import keras\n",
    "import keras_nlp\n",
    "from keras_nlp.models import GemmaBackbone, BertBackbone\n",
    "from keras.models import load_model\n",
    "import kagglehub\n",
    "import langchain_core\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.schema.runnable import Runnable\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from typing import Any, Optional\n",
    "import tensorflow as tf\n",
    "from keras.config import disable_interactive_logging\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0e6c309-c3f4-41c3-8af0-608a4ddc0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Global config\n",
    "#\n",
    "os.environ[\"GRPC_VERBOSITY\"] = \"ERROR\" # Try to suppress annoying GRPC warnings\n",
    "os.environ[\"GLOG_minloglevel\"] = \"3\"   # Try to suppress annoying GLOG warnings\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" # Try to suppress annoying TF CPP warnings\n",
    "# Try to suppress general warnings sent through the warnings module\n",
    "def warn(*args, **kwargs): \n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "disable_interactive_logging() # Try to support keras warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e85b0f34-f061-458a-9fc4-57f8c24e66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "#\n",
    "def makebold(txt):\n",
    "    return '\\x1b[1;30m'+txt+'\\x1b[0m'\n",
    "def makeblue(txt):\n",
    "    return '\\x1b[1;34m'+txt+'\\x1b[0m'\n",
    "def makegreen(txt):\n",
    "    return '\\x1b[1;32m'+txt+'\\x1b[0m'\n",
    "def makered(txt):\n",
    "    return '\\x1b[1;33m'+txt+'\\x1b[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6427861e-d331-4308-bb78-49d356ced65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Initial prompt - I'll use this prompt to contrast-and-compare various \n",
    "# prompt completion techniques using Keras\n",
    "#\n",
    "initial_prompt = \"Tell me a story. My name is Daniel.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24a19460-4b94-4b8f-805a-b7d086975f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mPrompt:\n",
      "\u001b[0m \u001b[1;32m\"Tell me a story. My name is Daniel.\"\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726940455.888266 11907544 service.cc:146] XLA service 0x600002b87f00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1726940455.888289 11907544 service.cc:154]   StreamExecutor device (0): Host, Default Version\n",
      "I0000 00:00:1726940455.892887 11907544 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30m\n",
      "Completion:\n",
      "\u001b[0m \u001b[1;34m\"Tell me a story. My name is Daniel.\n",
      "\n",
      "I was born and raised in a small coastal town in California called Santa Cruz. The ocean was my playground, and I spent countless hours swimming, surfing, and playing in the waves. I had a deep love for the ocean and all it had to offer.\n",
      "\n",
      "One fateful day, a storm hit Santa Cruz with devastating force. The powerful waves crashed over the coastline, destroying everything in their path. My beloved town was devastated, and I was heartbroken.\n",
      "\n",
      "But through the devastation, there were also glimmers of hope. The ocean had a way of reclaiming what it had lost, and new life emerged in the aftermath. The town was rebuilt, stronger than ever before.\n",
      "\n",
      "As I grew older, I realized that my passion for the sea had not changed. I still yearned for the calmness and beauty of the ocean, and I found solace in the memories of my childhood.\n",
      "\n",
      "Years later, I returned to Santa Cruz to rebuild my life. I had learned from my previous experience and was determined to make the town a better place for all.\n",
      "\n",
      "I started by creating a community garden, where people could come together and share their passion for nature. I also launched a youth sailing program, which aimed to introduce young people to the joy of sailing.\n",
      "\n",
      "The town was slowly but surely recovering, and I was proud to be a part of it. I had not only lost my hometown but had also gained a new sense of purpose.\n",
      "\n",
      "One day, I received a letter from a former student who had moved away. They told me that they were now a successful marine biologist, and they thanked me for inspiring them to pursue their dream.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean.\n",
      "\n",
      "I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "96399"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "#  Test a basic prompt completion using the model generate() call\n",
    "#\n",
    "model_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=3, seed=2)\n",
    "model_lm.compile(sampler=sampler)\n",
    "\n",
    "# Create the prompt via manual formatting\n",
    "template = \"{instruction}\" # Note: format may depend on the fine-tuning dataset format\n",
    "simple_prompt = template.format(\n",
    "    instruction=initial_prompt,\n",
    "    response=\"\",\n",
    ")\n",
    "print(makebold(\"Prompt:\\n\"), makegreen(\"\\\"\" + simple_prompt + \"\\\"\") )\n",
    "\n",
    "# Complete the prompt via model generate()\n",
    "model_prompt_completion = model_lm.generate(simple_prompt, max_length=2048) # Note: Using the context size of Gemma as max\n",
    "print(makebold(\"\\nCompletion:\\n\"), makeblue(\"\\\"\"+ model_prompt_completion + \"\\\"\" ))\n",
    "\n",
    "model_lm = None # clean up memory\n",
    "gc.collect() # Run python memory collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde23665-ec6a-49fe-939c-475f1336d2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mRunnable prompt:\n",
      "\u001b[0m\u001b[1;32m\"Tell me a story. My name is Daniel.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "Runnable completion:\n",
      "\u001b[0m\u001b[1;34m\"Tell me a story. My name is Daniel.\n",
      "\n",
      "I was born and raised in a small coastal town in California called Santa Cruz. The ocean was my playground, and I spent countless hours swimming, surfing, and playing in the waves. I had a deep love for the ocean and all it had to offer.\n",
      "\n",
      "One fateful day, a storm hit Santa Cruz with devastating force. The powerful waves crashed over the coastline, destroying everything in their path. My beloved town was devastated, and I was heartbroken.\n",
      "\n",
      "But through the devastation, there were also glimmers of hope. The ocean had a way of reclaiming what it had lost, and new life emerged in the aftermath. The town was rebuilt, stronger than ever before.\n",
      "\n",
      "As I grew older, I realized that my passion for the sea had not changed. I still yearned for the calmness and beauty of the ocean, and I found solace in the memories of my childhood.\n",
      "\n",
      "Years later, I returned to Santa Cruz to rebuild my life. I had learned from my previous experience and was determined to make the town a better place for all.\n",
      "\n",
      "I started by creating a community garden, where people could come together and share their passion for nature. I also launched a youth sailing program, which aimed to introduce young people to the joy of sailing.\n",
      "\n",
      "The town was slowly but surely recovering, and I was proud to be a part of it. I had not only lost my hometown but had also gained a new sense of purpose.\n",
      "\n",
      "One day, I received a letter from a former student who had moved away. They told me that they were now a successful marine biologist, and they thanked me for inspiring them to pursue their dream.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean.\n",
      "\n",
      "I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90275"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Test a basic prompt completion via a minimal Langchain Runnable\n",
    "# with minimal interaction\n",
    "#\n",
    "class LMRunnable(Runnable):\n",
    "    def __init__(self, model: keras_nlp.models.GemmaCausalLM):\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, input: Any, config: Optional[dict] = None) -> str:\n",
    "        prompt = str(input)\n",
    "        output = self.model.generate(prompt, max_length=2048)\n",
    "        return output \n",
    "\n",
    "# Use the Gemma model as a Langchain Runnable\n",
    "model_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=3, seed=2)\n",
    "model_lm.compile(sampler=sampler)\n",
    "runnable = LMRunnable(model_lm)\n",
    "\n",
    "# Create the prompt via manual formatting\n",
    "runnable_prompt = f\"{initial_prompt}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(makebold(\"Runnable prompt:\\n\") +  makegreen(\"\\\"\" + runnable_prompt + \"\\\"\") )\n",
    "\n",
    "# Complete the prompt via Runnable invoke()\n",
    "runnable_prompt_completion = runnable.invoke(runnable_prompt)\n",
    "print(makebold(\"\\nRunnable completion:\\n\") + makeblue(\"\\\"\" + runnable_prompt_completion + \"\\\"\"))\n",
    "\n",
    "runnable = None # release model handle\n",
    "model_lm = None # try to clean up model memory\n",
    "gc.collect() # Run python memory collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03fe49d0-2697-4e3b-86a2-a67df4fde849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mRunnable prompt from template:\n",
      "\u001b[0m\u001b[1;32m\"You are a writer of function.\n",
      "\n",
      "Tell me a story. My name is Daniel.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "Runnable completion:\n",
      "\u001b[0m\u001b[1;34m\"You are a writer of function.\n",
      "\n",
      "Tell me a story. My name is Daniel.\n",
      "\n",
      "I have a wife, Sarah, and we have two beautiful children, Emily and Daniel. I work as a software developer, and I am very passionate about my work. I am also very active in my community, and I volunteer my time to help others.\n",
      "\n",
      "My life has been filled with joy and sorrow, but through it all, I have learned that the most important thing is to be kind to others and to always be there for those I love.\n",
      "\n",
      "What is your story?\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90183"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Test a basic prompt completion via a minimal Langchain Runnable and ChatPromptTemplate\n",
    "#\n",
    "class LMRunnable(Runnable):\n",
    "    def __init__(self, model: keras_nlp.models.GemmaCausalLM):\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, input: Any, config: Optional[dict] = None) -> str: \n",
    "        if not isinstance(input,langchain_core.prompt_values.PromptValue):\n",
    "            raise Exception(\"Unknown input type\")\n",
    "        # Note the implementor of this class needs to know about the template\n",
    "        # in order to form the raw prompt to present to the model\n",
    "        raw_prompt = input.messages[0].content + \"\\n\\n\" + input.messages[1].content\n",
    "        output = self.model.generate(raw_prompt, max_length=2048)\n",
    "        return output \n",
    "\n",
    "# Use the Gemma model as a Langchain Runnable\n",
    "model_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=3, seed=2)\n",
    "model_lm.compile(sampler=sampler)\n",
    "runnable = LMRunnable(model_lm)\n",
    "\n",
    "# Create the prompt via a ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a writer of function.\"),\n",
    "    MessagesPlaceholder(\"msgs\")\n",
    "])\n",
    "\n",
    "# Make a prompt using the template just defined\n",
    "runnable_prompt_templ = prompt_template.invoke({\"msgs\": [HumanMessage(content=initial_prompt)]})\n",
    "print( makebold(\"Runnable prompt from template:\\n\") \\\n",
    "      + makegreen( \"\\\"\" + runnable_prompt_templ.messages[0].content + \"\\n\\n\" + \\\n",
    "                  runnable_prompt_templ.messages[1].content + \"\\\"\") )\n",
    "\n",
    "# Complete the prompt\n",
    "runnable_prompt_completion_templ = runnable.invoke(runnable_prompt_templ)\n",
    "print(makebold(\"\\nRunnable completion:\\n\") + makeblue(\"\\\"\" + runnable_prompt_completion_templ + \"\\\"\"))\n",
    "\n",
    "runnable = None # release model handle\n",
    "model_lm = None # try to clean up model memory\n",
    "gc.collect() # Run python memory collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e3f86c6-1e2c-4395-96ef-3adf4cef1097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mGemmaLocalKaggle prompt:\n",
      "\u001b[0m\u001b[1;32m\"Tell me a story. My name is Daniel.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "GemmaLocalKaggle completion:\n",
      "\u001b[0m \u001b[1;34m\"Tell me a story. My name is Daniel.\n",
      "\n",
      "I woke up in a small cottage nestled amongst the rolling hills. The morning sun painted the walls with warm golden hues, and the birds sang melodies that filled the air with joy.\n",
      "\n",
      "As I opened my eyes, I noticed a small cottage nestled amongst the rolling hills. The cottage was made of wood and stone, with a thatched roof that seemed to dance in the sunlight. A small door was open, inviting me inside.\n",
      "\n",
      "I stepped through the door and into the cozy interior. The walls were adorned with paintings of animals and landscapes, and the floor was covered with a soft rug. A fireplace crackled in the corner, casting warm shadows on the walls.\n",
      "\n",
      "A warm meal awaited me in the kitchen, along with a cozy bed to rest my head. I sat down at the table and enjoyed the simple yet delicious meal.\n",
      "\n",
      "As the sun began to set, I took a stroll outside the cottage, enjoying the fresh air and the stunning views. I watched as the birds flew around the hills, their colors shimmering in the golden light.\n",
      "\n",
      "That day, I learned the name of the cottage and the surrounding area. I met the kind old farmer who lived there, who welcomed me into his home and shared stories of the land.\n",
      "\n",
      "I spent the next few days exploring the area, discovering hidden waterfalls, lush forests, and charming villages. I learned about the local culture and traditions, and I made memories that would last a lifetime.\n",
      "\n",
      "One evening, as I sat by the fireplace, I heard a soft melody echoing through the hills. I followed the sound to a hidden spot, where I found a small cottage with a beautiful garden. The cottage belonged to a young woman named Sarah, who welcomed me in and showed me around her home.\n",
      "\n",
      "We talked for hours, sharing stories and laughter. I learned about her life, her dreams, and her aspirations. I was struck by her kindness and warmth, and I felt a deep connection to her.\n",
      "\n",
      "As the sun rose the next morning, I bid farewell to Sarah and the charming cottage. I knew that I would cherish the memories I had made during my stay.\n",
      "\n",
      "And so, my journey began, guided by the gentle hand of the sun and the kindness of strangers. I was Daniel, a traveler who found a home in the rolling hills and the hearts of the people I met along the way.\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89844"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Test a basic prompt completion using Langchain's GemmaLocalKaggle class\n",
    "# Documentation: https://python.langchain.com/api_reference/google_vertexai/gemma/langchain_google_vertexai.gemma.GemmaLocalKaggle.html\n",
    "#\n",
    "from langchain_google_vertexai import GemmaLocalKaggle\n",
    "glk_model = GemmaLocalKaggle(model_name=\"gemma_instruct_2b_en\", keras_backend=\"jax\")\n",
    "\n",
    "# Create the prompt via manual formatting\n",
    "glk_prompt = f\"{initial_prompt}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(makebold(\"GemmaLocalKaggle prompt:\\n\") + makegreen(\"\\\"\" + glk_prompt + \"\\\"\"))\n",
    "\n",
    "# Complete the prompt via invoke()\n",
    "glk_prompt_completion = glk_model.invoke(glk_prompt)\n",
    "print(makebold(\"\\nGemmaLocalKaggle completion:\\n\"), makeblue(\"\\\"\"+ glk_prompt_completion+ \"\\\"\") )\n",
    "\n",
    "glk_model = None # try to clean up model memory\n",
    "gc.collect() # Run python memory collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b44272d4-707f-4a45-8969-bcfb9d18211f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mGemmaChatLocalKaggle prompt:\n",
      "\u001b[0m \u001b[1;32m\"Tell me a story. My name is Daniel.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "GemmaChatLocalKaggle aimessage response object:\u001b[0m\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<start_of_turn>user\n",
      "Tell me a story. My name is Daniel.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "My name is Daniel, and I have a story to tell. I was born in a small village nestled amidst rolling hills and shimmering rivers. My childhood was filled with laughter and adventure, as I explored the lush forests and hidden waterfalls that surrounded our home.\n",
      "\n",
      "As I grew older, I became fascinated by the world beyond our village. I would spend countless hours gazing up at the vast expanse of the sky, wondering about the mysteries of the universe. My curiosity led me to explore nearby towns and cities, where I learned about different cultures and traditions.\n",
      "\n",
      "My thirst for knowledge never waned. I enrolled in a prestigious university, where I excelled in my studies. I was particularly drawn to the field of literature, where I discovered the power of words to transport me to different worlds and inspire me to think differently.\n",
      "\n",
      "After graduating, I returned to my village and took up a teaching position in a local school. I found joy in sharing my love of learning with young minds, and I became known for my patience and dedication.\n",
      "\n",
      "As the years passed, I met a wonderful woman named Sarah. We fell deeply in love and got married. We built a life together, filled with laughter, adventure, and a deep sense of connection.\n",
      "\n",
      "Through the years, I faced challenges and celebrated triumphs. I traveled the world, exploring different cultures and making lifelong friends. I learned the importance of compassion, forgiveness, and the power of kindness.\n",
      "\n",
      "Now, as an older man, I reflect on my life with gratitude. I have lived a full and meaningful life, surrounded by love and surrounded by the beauty of nature. I am proud of the person I have become, and I am eager to continue sharing my story with the world.\n",
      "\n",
      "My story is a testament to the power of curiosity, the importance of lifelong learning, and the enduring strength of love. It is a story that I will continue to tell, for it is a story that belongs to all of us.\n",
      "\u001b[1;30m\n",
      "GemmaChatLocalKaggle response only:\n",
      "\u001b[0m\u001b[1;34m\"My name is Daniel, and I have a story to tell. I was born in a small village nestled amidst rolling hills and shimmering rivers. My childhood was filled with laughter and adventure, as I explored the lush forests and hidden waterfalls that surrounded our home.\n",
      "\n",
      "As I grew older, I became fascinated by the world beyond our village. I would spend countless hours gazing up at the vast expanse of the sky, wondering about the mysteries of the universe. My curiosity led me to explore nearby towns and cities, where I learned about different cultures and traditions.\n",
      "\n",
      "My thirst for knowledge never waned. I enrolled in a prestigious university, where I excelled in my studies. I was particularly drawn to the field of literature, where I discovered the power of words to transport me to different worlds and inspire me to think differently.\n",
      "\n",
      "After graduating, I returned to my village and took up a teaching position in a local school. I found joy in sharing my love of learning with young minds, and I became known for my patience and dedication.\n",
      "\n",
      "As the years passed, I met a wonderful woman named Sarah. We fell deeply in love and got married. We built a life together, filled with laughter, adventure, and a deep sense of connection.\n",
      "\n",
      "Through the years, I faced challenges and celebrated triumphs. I traveled the world, exploring different cultures and making lifelong friends. I learned the importance of compassion, forgiveness, and the power of kindness.\n",
      "\n",
      "Now, as an older man, I reflect on my life with gratitude. I have lived a full and meaningful life, surrounded by love and surrounded by the beauty of nature. I am proud of the person I have become, and I am eager to continue sharing my story with the world.\n",
      "\n",
      "My story is a testament to the power of curiosity, the importance of lifelong learning, and the enduring strength of love. It is a story that I will continue to tell, for it is a story that belongs to all of us.\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89845"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Test a basic prompt completion using Langchain's GemmaChatLocalKaggle class\n",
    "# Documentation: https://python.langchain.com/api_reference/google_vertexai/gemma/langchain_google_vertexai.gemma.GemmaChatLocalKaggle.html\n",
    "#\n",
    "from langchain_google_vertexai import GemmaChatLocalKaggle\n",
    "gclk_model = GemmaChatLocalKaggle(model_name=\"gemma_instruct_2b_en\", keras_backend=\"jax\")\n",
    "\n",
    "# Create the prompt via manual formatting\n",
    "gclk_prompt = f\"{initial_prompt}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(makebold(\"GemmaChatLocalKaggle prompt:\\n\"), makegreen(\"\\\"\"+ gclk_prompt + \"\\\"\") )\n",
    "\n",
    "# Complete the prompt via invoke\n",
    "ai_message = gclk_model.invoke(gclk_prompt) # return a special aimessage object\n",
    "print(makebold(\"\\nGemmaChatLocalKaggle aimessage response object:\"))\n",
    "ai_message.pretty_print()\n",
    "# extract just the model completion from aimessage - vertexai appears to insert \"turn\" tags\n",
    "turn_prefix = \"<start_of_turn>model\\n\"\n",
    "pos = ai_message.content.find(turn_prefix)\n",
    "gclk_prompt_completion = ai_message.content[ pos + len(turn_prefix): ]\n",
    "\n",
    "print(makebold(\"\\nGemmaChatLocalKaggle response only:\\n\") + makeblue(\"\\\"\" + gclk_prompt_completion + \"\\\"\"))\n",
    "\n",
    "gclk_model = None # try to clean up model memory\n",
    "gc.collect() # Run python memory collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc0de4a5-ad8e-47e0-9fa3-035a8dfca22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The rest of this notebook attempts to integrate previous \"chat\" history\n",
    "# in various ways.    \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ffee5d4-b30e-4b8e-ab0a-883de0da9435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mCherry-picked history:\n",
      "\u001b[0m \u001b[1;33m\"It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean. I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "Continuation prompt:\n",
      "\u001b[0m \u001b[1;32m\"You are a writer of fiction. Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean. I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\"\u001b[0m\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <bound method GemmaCausalLM.generate_step of <GemmaCausalLM name=gemma_causal_lm_4, built=True>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1;30m\n",
      "Prompt completion:\n",
      "\u001b[0m \u001b[1;34m\"You are a writer of fiction. Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean. I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\n",
      "\n",
      "**Continue the Story**\n",
      "\n",
      "The sun rose over the shimmering waters of Santa Cruz, casting an ethereal glow upon the bustling streets below. The vibrant colors of life, from the bustling market vendors to the lively children chasing each other, painted the scene with an undeniable charm. I sat on the shore, watching the sunrise paint the sky with a breathtaking palette.\n",
      "\n",
      "As the morning sun continued to rise, casting its warm embrace upon the land, I felt a surge of energy coursing through my veins. I knew that this was the time to embark on my daily ritual.\n",
      "\n",
      "I grabbed my fishing net and headed towards the pier, my heart pounding with excitement. I had been looking forward to this moment for what felt like an eternity, and I knew that today would be a special one.\n",
      "\n",
      "As the sun rose, I cast my net into the clear waters, the rhythmic slap of the net against the sand a symphony of hope. I waited patiently, my senses heightened, for the first sign of a tug or a bite.\n",
      "\n",
      "And then, there it was – a gentle tug on the end of my line. My smile widened as I hauled in a plump, silvery fish, its scales shimmering in the morning sun. I couldn't help but grin ear to ear at the catch, a testament to the resilience and hope that lay within me.\n",
      "\n",
      "With the fish safely secured in my net, I watched as the sun rose higher, painting the sky with an even more magnificent palette. I sat there, enjoying the beauty of the moment, feeling a sense of contentment wash over me.\n",
      "\n",
      "As the day went on, I continued to fish with the same fervor, each cast bringing me closer to the bounty that awaited me. The sun climbed higher, casting its warm embrace upon the land, and the water grew calmer, allowing me to enjoy the serenity of the moment.\n",
      "\n",
      "By the time the sun began to set, I had filled my net with a variety of fresh fish, each one a testament to the enduring spirit of the ocean and the hope and resilience that resided within me. I sat on the shore, feeling the cool waves lap against my skin, a reminder of my roots and the countless blessings that surrounded me.\n",
      "\n",
      "As the sun dipped below the horizon, casting long shadows across the beach, I realized that my story was one of hope, resilience, and the enduring power of the ocean. The sun's descent was a symbol of the cycle of life, the ebb and flow that had shaped my own journey, and the unwavering spirit that would continue to guide me on my path to a better tomorrow.\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90273"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Continuation via model generate()\n",
    "#\n",
    "\n",
    "model_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=3, seed=2)\n",
    "model_lm.compile(sampler=sampler)\n",
    "\n",
    "# Extract the last two sentences of previous response as 'context' for the next prompt in the conversation/story.\n",
    "cherry_picked_history = \" \".join( model_prompt_completion.strip().split(\"\\n\\n\")[-2:] )\n",
    "print(makebold(\"Cherry-picked history:\\n\"), makered(\"\\\"\" + cherry_picked_history + \"\\\"\"))\n",
    "\n",
    "# Form the follow-up prompt.\n",
    "continuation_prompt = template.format(\n",
    "    instruction= f\"You are a writer of fiction. Use the following context and continue telling the story.\\n\\n{cherry_picked_history}\",\n",
    "    response=\"\",\n",
    ") # Note: That format may depend additional on the dataset used for fine-tuning\n",
    "print(makebold(\"\\nContinuation prompt:\\n\"), makegreen(\"\\\"\" + continuation_prompt + \"\\\"\"))\n",
    "\n",
    "# Complete the prompt via model generate()\n",
    "model_continuation_prompt_completion = model_lm.generate(continuation_prompt, max_length=2048) \n",
    "print(makebold(\"\\nPrompt completion:\\n\"), makeblue(\"\\\"\" + model_continuation_prompt_completion + \"\\\"\"))\n",
    "\n",
    "model_lm = None # try to clean up model memory\n",
    "gc.collect() # Run python memory collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71cae5fe-9823-45c5-a3a5-80fe87fa7bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mCherry-picked history:\n",
      "\u001b[0m \u001b[1;33m\"It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean. I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "Continuation prompt:\n",
      "\u001b[0m \u001b[1;32m\"You are a writer of fiction. Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean. I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\"\u001b[0m\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <bound method GemmaCausalLM.generate_step of <GemmaCausalLM name=gemma_causal_lm_5, built=True>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1;30m\n",
      "Prompt completiont:\n",
      "\u001b[0m \u001b[1;34m\"You are a writer of fiction. Use the following context and continue telling the story.\n",
      "\n",
      "It was then that I realized that my story was one of hope, resilience, and the enduring power of the ocean. I am Daniel, the son of Santa Cruz, and I will always be proud of my roots.\n",
      "\n",
      "**Continue the Story**\n",
      "\n",
      "The sun rose over the shimmering waters of Santa Cruz, casting an ethereal glow upon the bustling streets below. The vibrant colors of life, from the bustling market vendors to the lively children chasing each other, painted the scene with an undeniable charm. I sat on the shore, watching the sunrise paint the sky with a breathtaking palette.\n",
      "\n",
      "As the morning sun continued to rise, casting its warm embrace upon the land, I felt a surge of energy coursing through my veins. I knew that this was the time to embark on my daily ritual.\n",
      "\n",
      "I grabbed my fishing net and headed towards the pier, my heart pounding with excitement. I had been looking forward to this moment for what felt like an eternity, and I knew that today would be a special one.\n",
      "\n",
      "As the sun rose, I cast my net into the clear waters, the rhythmic slap of the net against the sand a symphony of hope. I waited patiently, my senses heightened, for the first sign of a tug or a bite.\n",
      "\n",
      "And then, there it was – a gentle tug on the end of my line. My smile widened as I hauled in a plump, silvery fish, its scales shimmering in the morning sun. I couldn't help but grin ear to ear at the catch, a testament to the resilience and hope that lay within me.\n",
      "\n",
      "With the fish safely secured in my net, I watched as the sun rose higher, painting the sky with an even more magnificent palette. I sat there, enjoying the beauty of the moment, feeling a sense of contentment wash over me.\n",
      "\n",
      "As the day went on, I continued to fish with the same fervor, each cast bringing me closer to the bounty that awaited me. The sun climbed higher, casting its warm embrace upon the land, and the water grew calmer, allowing me to enjoy the serenity of the moment.\n",
      "\n",
      "By the time the sun began to set, I had filled my net with a variety of fresh fish, each one a testament to the enduring spirit of the ocean and the hope and resilience that resided within me. I sat on the shore, feeling the cool waves lap against my skin, a reminder of my roots and the countless blessings that surrounded me.\n",
      "\n",
      "As the sun dipped below the horizon, casting long shadows across the beach, I realized that my story was one of hope, resilience, and the enduring power of the ocean. The sun's descent was a symbol of the cycle of life, the ebb and flow that had shaped my own journey, and the unwavering spirit that would continue to guide me on my path to a better tomorrow.\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90284"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Continuation via a basic Langchain Runnable\n",
    "#\n",
    "class LMRunnable(Runnable):\n",
    "    def __init__(self, model: keras_nlp.models.GemmaCausalLM):\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, input: Any, config: Optional[dict] = None) -> str:\n",
    "        prompt = str(input)\n",
    "        output = self.model.generate(prompt, max_length=2048)\n",
    "        return output if isinstance(output,str) else \"Unknown output type.\"\n",
    "\n",
    "# Use the (previously compiled) Gemma model as a Langchain Runnable\n",
    "model_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_instruct_2b_en\")\n",
    "sampler = keras_nlp.samplers.TopKSampler(k=3, seed=2)\n",
    "model_lm.compile(sampler=sampler)\n",
    "runnable = LMRunnable(model_lm)\n",
    "\n",
    "# Extract the last two sentences of previous response as 'context' for the next prompt in the conversation/story.\n",
    "cherry_picked_history = \" \".join( runnable_prompt_completion.strip().split(\"\\n\\n\")[-2:] )\n",
    "print(makebold(\"Cherry-picked history:\\n\"), makered( \"\\\"\" + cherry_picked_history + \"\\\"\"))\n",
    "\n",
    "# Create the prompt via manual formatting\n",
    "continuation_prompt = f\"You are a writer of fiction. Use the following context and continue telling the story.\\n\\n{cherry_picked_history}\"\n",
    "print(makebold(\"\\nContinuation prompt:\\n\"), makegreen(\"\\\"\" + continuation_prompt + \"\\\"\"))\n",
    "\n",
    "# Complete the prompt via Runnable invoke()\n",
    "runnable_continuation_prompt_completion = runnable.invoke(continuation_prompt)\n",
    "print(makebold(\"\\nPrompt completiont:\\n\"), makeblue(\"\\\"\" + runnable_continuation_prompt_completion + \"\\\"\"))\n",
    "\n",
    "runnable = None # release model handle\n",
    "model_lm = None # try to clean up model memory\n",
    "gc.collect() # Run python memory collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ca1586a-c934-475c-9d92-5642147623f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mCherry-picked history:\n",
      "\u001b[0m \u001b[1;33m\"As the sun rose the next morning, I bid farewell to Sarah and the charming cottage. I knew that I would cherish the memories I had made during my stay. And so, my journey began, guided by the gentle hand of the sun and the kindness of strangers. I was Daniel, a traveler who found a home in the rolling hills and the hearts of the people I met along the way.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "GemmaLocalKaggle prompt:\n",
      "\u001b[0m\u001b[1;32m\"You are a writer of fiction. Use the following context and continue telling the story.\n",
      "\n",
      "As the sun rose the next morning, I bid farewell to Sarah and the charming cottage. I knew that I would cherish the memories I had made during my stay. And so, my journey began, guided by the gentle hand of the sun and the kindness of strangers. I was Daniel, a traveler who found a home in the rolling hills and the hearts of the people I met along the way.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "GemmaLocalKaggle completion:\n",
      "\u001b[0m \u001b[1;34m\"You are a writer of fiction. Use the following context and continue telling the story.\n",
      "\n",
      "As the sun rose the next morning, I bid farewell to Sarah and the charming cottage. I knew that I would cherish the memories I had made during my stay. And so, my journey began, guided by the gentle hand of the sun and the kindness of strangers. I was Daniel, a traveler who found a home in the rolling hills and the hearts of the people I met along the way.\n",
      "\n",
      "The days were filled with adventure and discovery. I explored the hidden trails of the forest, stumbled upon ancient ruins, and learned the language of the birds. I met a wise old woman who taught me the secrets of the land, and I shared stories of my own with the villagers who welcomed me into their homes.\n",
      "\n",
      "As the sun began to set each day, I would sit by the river, watching the colors dance on the water. The gentle breeze carried the scent of wildflowers, and the stars emerged like a tapestry across the sky. It was then that I truly understood the beauty of my existence, a traveler lost in a world of wonder and kindness.\n",
      "\n",
      "One evening, as I sat by the river, I heard a soft melody echoing through the trees. It was the music of a young musician, his fingers dancing across the strings of his guitar. I watched as he sang, his voice filled with passion and longing. I knew that I had found a kindred spirit, a fellow wanderer who shared my love for the beauty of life.\n",
      "\n",
      "The next morning, I bid farewell to Sarah and the charming cottage. I knew that I would cherish the memories I had made during my stay. And so, my journey continued, guided by the gentle hand of the sun and the kindness of strangers. I was Daniel, a traveler who found a home in the rolling hills and the hearts of the people I met along the way.\u001b[0m\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Continuation via Langchain's GemmaLocalKaggle class\n",
    "# Documentation: https://python.langchain.com/api_reference/google_vertexai/gemma/langchain_google_vertexai.gemma.GemmaLocalKaggle.html\n",
    "#\n",
    "from langchain_google_vertexai import GemmaLocalKaggle\n",
    "glk_model = GemmaLocalKaggle(model_name=\"gemma_instruct_2b_en\", keras_backend=\"jax\")\n",
    "\n",
    "# Extract the last two sentences of previous response as 'context' for the next prompt in the conversation/story.\n",
    "cherry_picked_history = \" \".join( glk_prompt_completion.strip().split(\"\\n\\n\")[-2:] )\n",
    "print(makebold(\"Cherry-picked history:\\n\"), makered( \"\\\"\" + cherry_picked_history + \"\\\"\"))\n",
    "\n",
    "# Complete the prompt via Runnable invoke()\n",
    "glk_continuation_prompt = f\"You are a writer of fiction. Use the following context and continue telling the story.\\n\\n{cherry_picked_history}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(makebold(\"\\nGemmaLocalKaggle prompt:\\n\") + makegreen(\"\\\"\" + glk_continuation_prompt + \"\\\"\"))\n",
    "\n",
    "# Complete the prompt via invoke()\n",
    "glk_continuation_prompt_completion = glk_model.invoke(glk_continuation_prompt)\n",
    "print(makebold(\"\\nGemmaLocalKaggle completion:\\n\"), makeblue(\"\\\"\" + glk_continuation_prompt_completion) + \"\\\"\")\n",
    "\n",
    "glk_model # try to clean up model memory\n",
    "gc.collect() # Run python memory collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "017488af-d84c-4acf-a289-6b37b62c8851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30mCherry-picked history:\n",
      "\u001b[0m \u001b[1;33m\" My story is a testament to the power of curiosity, the importance of lifelong learning, and the enduring strength of love. It is a story that I will continue to tell, for it is a story that belongs to all of us.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "GemmaChatLocalKaggle prompt:\n",
      "\u001b[0m \u001b[1;32m\"You are a storyteller.  Use the following context and continue telling the story.\n",
      "\n",
      " My story is a testament to the power of curiosity, the importance of lifelong learning, and the enduring strength of love. It is a story that I will continue to tell, for it is a story that belongs to all of us.\"\u001b[0m\n",
      "\u001b[1;30m\n",
      "GemmaChatLocalKaggle aimessage response object:\u001b[0m\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<start_of_turn>user\n",
      "You are a storyteller.  Use the following context and continue telling the story.\n",
      "\n",
      " My story is a testament to the power of curiosity, the importance of lifelong learning, and the enduring strength of love. It is a story that I will continue to tell, for it is a story that belongs to all of us.<end_of_turn>\n",
      "<start_of_turn>model\n",
      "The old library, with its towering bookshelves and the musty scent of aged paper, was my sanctuary. I would spend countless hours there, lost in the worlds spun by the pages of countless books.\n",
      "\n",
      "One day, a young girl with eyes as bright as the summer sky entered the library. She was captivated by the stories she found, her imagination running wild as she devoured each book she could lay her hands on.\n",
      "\n",
      "I took her under my wing, becoming her guide through the vast world of knowledge. We spent hours exploring the ancient tales of heroes and villains, the captivating mysteries of ancient civilizations, and the enchanting tales of faraway lands.\n",
      "\n",
      "As she grew older, so did my love for her. I saw in her the same spark of curiosity that had ignited my own passion for learning. We spent our days exploring the world together, learning new things every day.\n",
      "\n",
      "Years passed, and the library became our sanctuary. We were inseparable, our bond unbreakable. We shared our dreams, our fears, and our laughter. The library was our refuge, a place where we could escape the chaos of the outside world and find solace in the pages of a book.\n",
      "\n",
      "One day, the library was forced to close its doors. A fire had swept through the building, destroying countless books and leaving the library in ruins. But my love for the library and its magic never faded.\n",
      "\n",
      "I knew that the library's spirit would never truly die. It would live on in the hearts of those who cherished its stories, in the countless children who dreamed of discovering the world through the magic of books.\n",
      "\n",
      "So, I vowed to keep telling the stories of the library, to keep inspiring future generations to explore the world through the power of books. I knew that the library's legacy would live on, not only in the books I wrote but also in the countless lives I touched.\n",
      "\n",
      "And so, I continue to tell the story of the library, a story that belongs to all of us. A story of curiosity, lifelong learning, and the enduring strength of love.\n",
      "\u001b[1;30m\n",
      "GemmaChatLocalKaggle response only:\n",
      "\u001b[0m\u001b[1;34m\"The old library, with its towering bookshelves and the musty scent of aged paper, was my sanctuary. I would spend countless hours there, lost in the worlds spun by the pages of countless books.\n",
      "\n",
      "One day, a young girl with eyes as bright as the summer sky entered the library. She was captivated by the stories she found, her imagination running wild as she devoured each book she could lay her hands on.\n",
      "\n",
      "I took her under my wing, becoming her guide through the vast world of knowledge. We spent hours exploring the ancient tales of heroes and villains, the captivating mysteries of ancient civilizations, and the enchanting tales of faraway lands.\n",
      "\n",
      "As she grew older, so did my love for her. I saw in her the same spark of curiosity that had ignited my own passion for learning. We spent our days exploring the world together, learning new things every day.\n",
      "\n",
      "Years passed, and the library became our sanctuary. We were inseparable, our bond unbreakable. We shared our dreams, our fears, and our laughter. The library was our refuge, a place where we could escape the chaos of the outside world and find solace in the pages of a book.\n",
      "\n",
      "One day, the library was forced to close its doors. A fire had swept through the building, destroying countless books and leaving the library in ruins. But my love for the library and its magic never faded.\n",
      "\n",
      "I knew that the library's spirit would never truly die. It would live on in the hearts of those who cherished its stories, in the countless children who dreamed of discovering the world through the magic of books.\n",
      "\n",
      "So, I vowed to keep telling the stories of the library, to keep inspiring future generations to explore the world through the power of books. I knew that the library's legacy would live on, not only in the books I wrote but also in the countless lives I touched.\n",
      "\n",
      "And so, I continue to tell the story of the library, a story that belongs to all of us. A story of curiosity, lifelong learning, and the enduring strength of love.\"\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89845"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Continuation via Langchain's GemmaChatLocalKaggle class\n",
    "# Documentation: https://python.langchain.com/api_reference/google_vertexai/gemma/langchain_google_vertexai.gemma.GemmaChatLocalKaggle.html\n",
    "#\n",
    "from langchain_google_vertexai import GemmaChatLocalKaggle\n",
    "gclk_model = GemmaChatLocalKaggle(model_name=\"gemma_instruct_2b_en\", keras_backend=\"jax\")\n",
    "\n",
    "# Extract the last two sentences of previous response as 'context' for the next prompt in the conversation/story.\n",
    "cherry_picked_history = \" \".join( gclk_prompt_completion.strip().split(\"\\n\")[-2:] )\n",
    "print(makebold(\"Cherry-picked history:\\n\"), makered(\"\\\"\" + cherry_picked_history + \"\\\"\"))\n",
    "\n",
    "# Create the prompt via manual formatting\n",
    "gclk_continuation_prompt = f\"You are a storyteller.  Use the following context and continue telling the story.\\n\\n{cherry_picked_history}\" # Note: format may depend on the fine-tuning dataset format\n",
    "print(makebold(\"\\nGemmaChatLocalKaggle prompt:\\n\"), makegreen( \"\\\"\" + gclk_continuation_prompt + \"\\\"\") )\n",
    "\n",
    "# Complete the prompt via invoke()\n",
    "ai_message = gclk_model.invoke(gclk_continuation_prompt) # return a special aimessage object\n",
    "print(makebold(\"\\nGemmaChatLocalKaggle aimessage response object:\"))\n",
    "ai_message.pretty_print()\n",
    "# extract just the model completion from aimessage - vertexai appears to insert \"turn\" tags\n",
    "turn_prefix = \"<start_of_turn>model\\n\"\n",
    "pos = ai_message.content.find(turn_prefix)\n",
    "gclk_prompt_completion = ai_message.content[ pos + len(turn_prefix): ]\n",
    "\n",
    "print(makebold(\"\\nGemmaChatLocalKaggle response only:\\n\") + makeblue( \"\\\"\" + gclk_prompt_completion + \"\\\"\"))\n",
    "\n",
    "gclk_model = None # try to clean up model memory\n",
    "gc.collect() # Run python memory collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6064e583-da03-4286-9168-bee1b87ae8aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
